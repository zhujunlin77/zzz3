import os
import json
import cv2
from datetime import datetime
import numpy as np
import random
import re  # å¯¼å…¥æ­£åˆ™è¡¨è¾¾å¼æ¨¡å—
from lib.utils.opts import opts

def robust_yolo_to_coco_converter():
    """
    ä¸€ä¸ªå¥å£®çš„ã€æ”¯æŒå¤šåˆ†è¾¨ç‡å’Œæ¡ä»¶æŠ½å¸§çš„YOLOåˆ°COCOæ ¼å¼è½¬æ¢å™¨ã€‚
    - [æ ¸å¿ƒåŠŸèƒ½] è‡ªåŠ¨è¯»å–æ¯å¼ å›¾ç‰‡çš„å®é™…åˆ†è¾¨ç‡ï¼Œä¸å†ä¾èµ–å›ºå®šçš„IMAGE_W/Hã€‚
    - [æ ¸å¿ƒåŠŸèƒ½] ä»…å¯¹åç§°ä¸ç¬¦åˆ 'data' + æ•°å­— æ ¼å¼çš„æ–‡ä»¶å¤¹è¿›è¡ŒæŠ½å¸§ã€‚
    - èƒ½å¤Ÿè‡ªåŠ¨å‘ç°æ•°æ®æ–‡ä»¶å¤¹ã€‚
    - ç”¨æˆ·åªéœ€æ˜ç¡®æŒ‡å®šæµ‹è¯•é›†æ–‡ä»¶å¤¹ã€‚
    - æ”¯æŒå¤šç±»åˆ«ã€‚
    """
    # ==================== [ä¿®å¤ argparse é”™è¯¯] ====================
    # ä¼ å…¥ç©ºåˆ—è¡¨ï¼Œé˜²æ­¢è§£æä¸å¿…è¦çš„å‘½ä»¤è¡Œå‚æ•°
    try:
        opt = opts().parse([])
    except SystemExit:
        # argparse in notebook environments can cause sys.exit().
        # We can create a simple object to hold default paths.
        class SimpleOpts:
            def __init__(self):
                # åœ¨è¿™é‡Œè®¾ç½®ä¸€ä¸ªé»˜è®¤çš„æ•°æ®ç›®å½•ï¼Œä»¥é˜²optsåˆå§‹åŒ–å¤±è´¥
                self.data_dir = '/root/autodl-tmp/mix_scene'
        print("argparse exited, using default paths.")
        opt = SimpleOpts()
    except Exception as e:
        print(f"æ— æ³•åˆå§‹åŒ–optsï¼Œå°†ä½¿ç”¨é»˜è®¤è·¯å¾„ï¼š{e}")
        class SimpleOpts:
            def __init__(self):
                self.data_dir = '/root/autodl-tmp/mix_scene'
        opt = SimpleOpts()
    # ==========================================================

    # 1. åŸºç¡€è·¯å¾„é…ç½®
    scene_dir = getattr(opt, 'data_dir', '/root/autodl-tmp/mix_scene')
    target_dir = scene_dir
    images_base_dir = os.path.join(scene_dir, "images")
    labels_base_dir = os.path.join(scene_dir, "labels")

    # 2. æ•°æ®é›†åˆ’åˆ†
    print("ğŸš€ æ­¥éª¤1: åŠ¨æ€å‘ç°æ–‡ä»¶å¤¹å¹¶åˆ’åˆ†æ•°æ®é›†...")
    if not os.path.exists(images_base_dir):
        print(f"âŒ é”™è¯¯: 'images' ç›®å½•ä¸å­˜åœ¨äº: {images_base_dir}")
        return False
    
    all_data_folders = sorted([d for d in os.listdir(images_base_dir) if os.path.isdir(os.path.join(images_base_dir, d))])
    print(f"ğŸ” åœ¨ '{images_base_dir}' ä¸­å‘ç° {len(all_data_folders)} ä¸ªæ•°æ®æ–‡ä»¶å¤¹ã€‚")
    
    # --- ç”¨æˆ·éœ€è¦åœ¨æ­¤å¤„å®šä¹‰æµ‹è¯•é›† ---
    test_data_folders = [
        'wg2022_ir_020_split_01',
        'wg2022_ir_020_split_03',
        'wg2022_ir_020_split_07',
        # ... åœ¨æ­¤ç»§ç»­æ·»åŠ æ‚¨æ‰€æœ‰çš„æµ‹è¯•æ–‡ä»¶å¤¹ ...
    ]
    test_data_folders = all_data_folders
    train_data_folders = [f for f in all_data_folders if f not in test_data_folders]
    train_data_folders = ['data1','data2','data3','data1001','data1002','data1003',
        'wg2022_ir_020_split_01',
        'wg2022_ir_020_split_03',
        'wg2022_ir_020_split_07',
        # ... åœ¨æ­¤ç»§ç»­æ·»åŠ æ‚¨æ‰€æœ‰çš„æµ‹è¯•æ–‡ä»¶å¤¹ ...
    ]
    test_data_folders = train_data_folders

    print(f"âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆ: {len(train_data_folders)} è®­ç»ƒé›†, {len(test_data_folders)} æµ‹è¯•é›†")

    annotations_output_dir = os.path.join(target_dir, "annotations")
    os.makedirs(annotations_output_dir, exist_ok=True)

    def create_coco_format():
        return {
            "info": {"description": "Custom Dataset", "version": "1.0", "year": datetime.now().year,
                     "date_created": datetime.now().strftime("%Y-%m-%d")},
            "licenses": [{"id": 1, "name": "Unknown"}], "images": [], "annotations": [], "categories": []
        }

    # 3. ç±»åˆ«å®šä¹‰
    print("\nğŸ” æ­¥éª¤2: å®šä¹‰ç±»åˆ«ä¿¡æ¯...")
    yolo_class_names = ["drone", "car", "ship", "bus", "pedestrian", "cyclist"]
    categories = [{"id": i + 1, "name": name, "supercategory": "object"} for i, name in enumerate(yolo_class_names)]
    yolo_to_coco_mapping = {i: i + 1 for i in range(len(yolo_class_names))}
    print(f"ğŸ“‹ æˆåŠŸå®šä¹‰ {len(categories)} ä¸ªç±»åˆ«ã€‚")

    def process_dataset(data_folders_list, dataset_type, coco_data, frame_skip_rate_default=3):
        """
        å¤„ç†æŒ‡å®šçš„æ•°æ®é›†æ–‡ä»¶å¤¹åˆ—è¡¨ã€‚
        - åªæœ‰å½“æ–‡ä»¶å¤¹åç§°ä¸ç¬¦åˆ 'data' + æ•°å­— çš„æ ¼å¼æ—¶ï¼Œæ‰åº”ç”¨æŠ½å¸§ã€‚
        - åŠ¨æ€è¯»å–æ¯å¼ å›¾ç‰‡çš„å®é™…åˆ†è¾¨ç‡ã€‚
        """
        print(f"\n  ğŸ“‚ æ­£åœ¨å¤„ç† {dataset_type} æ•°æ®é›† ({len(data_folders_list)} ä¸ªæ–‡ä»¶å¤¹)...")
        print(f"   - é»˜è®¤æŠ½å¸§ç‡ (å½“æ–‡ä»¶å¤¹åç§°ä¸åŒ¹é…æ—¶): 1/{frame_skip_rate_default}")
            
        image_id_counter = len(coco_data["images"]) + 1
        annotation_id_counter = len(coco_data["annotations"]) + 1

        for data_folder in data_folders_list:
            image_dir = os.path.join(images_base_dir, data_folder)
            label_dir = os.path.join(labels_base_dir, data_folder)
            
            if not os.path.exists(image_dir) or not os.path.exists(label_dir):
                print(f"   - âš ï¸  è·³è¿‡ '{data_folder}' (ç›®å½•ä¸å­˜åœ¨)")
                continue

            # ==================== [æ¡ä»¶æŠ½å¸§é€»è¾‘] ====================
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… 'data' åè·Ÿä»»æ„æ•°å­—çš„æ¨¡å¼
            is_no_skip_folder = re.match(r'^data\d+$', data_folder)
            
            if is_no_skip_folder:
                current_frame_skip_rate = 1 # ä¸æŠ½å¸§
                # print(f"   -> æ–‡ä»¶å¤¹ '{data_folder}' åŒ¹é…æ¨¡å¼ï¼Œä¸æŠ½å¸§ (1/1)ã€‚") # å¯é€‰çš„è¯¦ç»†æ—¥å¿—
            else:
                current_frame_skip_rate = frame_skip_rate_default
                # if current_frame_skip_rate > 1:
                #     print(f"   -> æ–‡ä»¶å¤¹ '{data_folder}' ä¸åŒ¹é…ï¼Œåº”ç”¨æŠ½å¸§ (1/{current_frame_skip_rate})ã€‚") # å¯é€‰çš„è¯¦ç»†æ—¥å¿—
            # ==========================================================

            def natural_sort_key(s):
                return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', s)]
            image_files = sorted([f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))], key=natural_sort_key)

            for image_index, image_file in enumerate(image_files):
                if image_index % current_frame_skip_rate != 0:
                    continue

                label_full_path = os.path.join(label_dir, os.path.splitext(image_file)[0] + '.txt')
                if not os.path.exists(label_full_path):
                    continue

                # åŠ¨æ€è¯»å–å›¾åƒå°ºå¯¸
                image_full_path = os.path.join(image_dir, image_file)
                try:
                    img = cv2.imread(image_full_path)
                    if img is None:
                        continue
                    image_h, image_w = img.shape[:2]
                except Exception:
                    continue

                relative_image_path = os.path.join('images', data_folder, image_file).replace(os.sep, '/')
                
                image_info = {
                    "id": image_id_counter, "width": image_w, "height": image_h,
                    "file_name": relative_image_path, "license": 1, "original_file": image_file
                }
                coco_data["images"].append(image_info)

                with open(label_full_path, 'r') as f:
                    for line in f:
                        parts = line.strip().split()
                        if len(parts) < 5: continue
                        yolo_class_id, x_c, y_c, w, h = map(float, parts[:5])
                        yolo_class_id = int(yolo_class_id)
                        
                        # ä½¿ç”¨åŠ¨æ€å°ºå¯¸è¿›è¡Œè½¬æ¢
                        abs_w, abs_h = w * image_w, h * image_h
                        x_min, y_min = (x_c * image_w) - (abs_w / 2), (y_c * image_h) - (abs_h / 2)
                        
                        coco_category_id = yolo_to_coco_mapping.get(yolo_class_id)
                        if coco_category_id is None: continue

                        annotation = {
                            "id": annotation_id_counter, "image_id": image_id_counter,
                            "category_id": coco_category_id, "bbox": [x_min, y_min, abs_w, abs_h],
                            "area": abs_w * abs_h, "iscrowd": 0, "segmentation": []
                        }
                        coco_data["annotations"].append(annotation)
                        annotation_id_counter += 1
                image_id_counter += 1

    # 4. ç”Ÿæˆæ•°æ®é›†
    # ç”Ÿæˆè®­ç»ƒé›†ï¼ˆåº”ç”¨æ¡ä»¶æŠ½å¸§ï¼‰
    train_coco = create_coco_format()
    train_coco["categories"] = categories
    process_dataset(train_data_folders, "train", train_coco, frame_skip_rate_default=3) 

    # ç”Ÿæˆæµ‹è¯•é›†ï¼ˆä¸æŠ½å¸§ï¼‰
    test_coco = create_coco_format()
    test_coco["categories"] = categories
    process_dataset(test_data_folders, "test", test_coco, frame_skip_rate_default=1) 

    # 5. ä¿å­˜æ–‡ä»¶
    print("\nğŸ”§ æ­¥éª¤3: ä¿å­˜æ³¨é‡Šæ–‡ä»¶...")
    for (name, data) in [("train", train_coco), ("test", test_coco), ("val", test_coco)]:
        file_path = os.path.join(annotations_output_dir, f"instances_{name}2017.json")
        with open(file_path, 'w') as f:
            json.dump(data, f, indent=2)
        print(
            f"âœ… {name.capitalize()}é›†æ³¨é‡Šæ–‡ä»¶: {file_path} ({len(data['images'])} å›¾åƒ, {len(data['annotations'])} æ ‡æ³¨)")

    print("\nğŸ‰ æ•°æ®è½¬æ¢å®Œæˆ!")
    return True


if __name__ == "__main__":
    if robust_yolo_to_coco_converter():
        print("\nâœ… è½¬æ¢æˆåŠŸï¼ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒã€‚")
    else:
        print("\nâŒ è½¬æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯æ—¥å¿—ã€‚")